{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy\n",
    "# import tensorflow as tf\n",
    "import os\n",
    "import multiprocessing\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# import keras\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from tqdm import *\n",
    "from evaluate import evaluate\n",
    "import tensorflow as tf\n",
    "# import keras.backend as K\n",
    "# from keras.layers import *\n",
    "from models import *\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from models_encodercat import Encoder_Model\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T06:05:34.091827Z",
     "start_time": "2024-07-23T06:05:30.535012Z"
    }
   },
   "id": "3cbea27d71aad0c7",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "alignment_pair = [\n",
    "    (1, 101), (2, 102), (3, 103), (4, 104), (5, 105),\n",
    "    (6, 106), (7, 107), (8, 108), (9, 109), (10, 110)\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-23T05:48:45.870508Z",
     "start_time": "2024-07-23T05:48:45.867075Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_ratio = 0.3\n",
    "val_rate = 0.1\n",
    "np.random.shuffle(alignment_pair)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T05:48:47.130348Z",
     "start_time": "2024-07-23T05:48:47.127410Z"
    }
   },
   "id": "b8bb97f13ff1d009",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(alignment_pair)*round(train_ratio-val_rate,1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T05:49:53.903401Z",
     "start_time": "2024-07-23T05:49:53.899412Z"
    }
   },
   "id": "50dda92f8f47af7f",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(alignment_pair)*train_ratio)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T05:50:28.831012Z",
     "start_time": "2024-07-23T05:50:28.827473Z"
    }
   },
   "id": "dd326868346bcd2e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(alignment_pair)*train_ratio)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T05:50:46.041297Z",
     "start_time": "2024-07-23T05:50:46.037452Z"
    }
   },
   "id": "506da8fa2428789c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def normalize_adj(adj):\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return d_mat_inv_sqrt.dot(adj).transpose().dot(d_mat_inv_sqrt).T\n",
    "\n",
    "def load_triples(file_name):\n",
    "    triples = []\n",
    "    entity = set()\n",
    "    rel = set([0])\n",
    "    for line in open(file_name,'r'):\n",
    "        head,r,tail = [int(item) for item in line.split()]\n",
    "        entity.add(head); entity.add(tail); rel.add(r+1)\n",
    "        triples.append((head,r+1,tail))\n",
    "    return entity,rel,triples\n",
    "\n",
    "def load_alignment_pair(file_name):\n",
    "    alignment_pair = []\n",
    "    c = 0\n",
    "    for line in open(file_name,'r'):\n",
    "        e1,e2 = line.split()\n",
    "        alignment_pair.append((int(e1),int(e2)))\n",
    "    return alignment_pair\n",
    "\n",
    "def get_matrix(triples,entity,rel):\n",
    "        ent_size = max(entity)+1\n",
    "        rel_size = (max(rel) + 1)\n",
    "        print(ent_size,rel_size)\n",
    "        adj_matrix = sp.lil_matrix((ent_size,ent_size))\n",
    "        adj_features = sp.lil_matrix((ent_size,ent_size))\n",
    "        radj = []\n",
    "        rel_in = np.zeros((ent_size,rel_size))\n",
    "        rel_out = np.zeros((ent_size,rel_size))\n",
    "        \n",
    "        for i in range(max(entity)+1):\n",
    "            adj_features[i,i] = 1\n",
    "\n",
    "        for h,r,t in triples:        \n",
    "            adj_matrix[h,t] = 1; adj_matrix[t,h] = 1;\n",
    "            adj_features[h,t] = 1; adj_features[t,h] = 1;\n",
    "            radj.append([h,t,r]); radj.append([t,h,r+rel_size]); \n",
    "            rel_out[h][r] += 1; rel_in[t][r] += 1\n",
    "            \n",
    "        count = -1\n",
    "        s = set()\n",
    "        d = {}\n",
    "        r_index,r_val = [],[]\n",
    "        for h,t,r in sorted(radj,key=lambda x: x[0]*10e10+x[1]*10e5):\n",
    "            if ' '.join([str(h),str(t)]) in s:\n",
    "                r_index.append([count,r])\n",
    "                r_val.append(1)\n",
    "                d[count] += 1\n",
    "            else:\n",
    "                count += 1\n",
    "                d[count] = 1\n",
    "                s.add(' '.join([str(h),str(t)]))\n",
    "                r_index.append([count,r])\n",
    "                r_val.append(1)\n",
    "        for i in range(len(r_index)):\n",
    "            r_val[i] /= d[r_index[i][0]]\n",
    "        \n",
    "        rel_features = np.concatenate([rel_in,rel_out],axis=1)\n",
    "        adj_features = normalize_adj(adj_features)\n",
    "        rel_features = normalize_adj(sp.lil_matrix(rel_features))    \n",
    "        return adj_matrix,r_index,r_val,adj_features,rel_features  \n",
    "\n",
    "def load_data(lang, train_ratio = 0.3):\n",
    "    entity1,rel1,triples1 = load_triples(lang + 'triples_1')\n",
    "    entity2,rel2,triples2 = load_triples(lang + 'triples_2')\n",
    "    val_rate=0.1\n",
    "    if \"_en\" in lang:\n",
    "        alignment_pair = load_alignment_pair(lang + 'ref_ent_ids')\n",
    "        np.random.shuffle(alignment_pair)\n",
    "        train_pair,valid_pair,dev_pair = alignment_pair[0:int(len(alignment_pair)*round(train_ratio-val_rate,1))],alignment_pair[int(len(alignment_pair)*round(train_ratio-val_rate,1)):int(len(alignment_pair)*train_ratio)],alignment_pair[int(len(alignment_pair)*train_ratio):]\n",
    "    else:\n",
    "        train_pair = load_alignment_pair(lang + 'sup_ent_ids')\n",
    "        dev_pair = load_alignment_pair(lang + 'ref_ent_ids')\n",
    "        ae_features = None\n",
    "    \n",
    "    adj_matrix,r_index,r_val,adj_features,rel_features = get_matrix(triples1+triples2,entity1.union(entity2),rel1.union(rel2))\n",
    "\n",
    "    return np.array(train_pair),np.array(valid_pair),np.array(dev_pair),adj_matrix,np.array(r_index),np.array(r_val),adj_features, rel_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T06:04:22.945648Z",
     "start_time": "2024-07-23T06:04:22.932117Z"
    }
   },
   "id": "c1c5c6193aacb0b9",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38960 3025\n"
     ]
    }
   ],
   "source": [
    "data_ca=\"zh_en/\"\n",
    "data_dir = 'data/'+data_ca\n",
    "train_pair,val_pair,dev_pair,adj_matrix,r_index,r_val,adj_features,rel_features = load_data(data_dir,train_ratio=0.30)\n",
    "adj_matrix = np.stack(adj_matrix.nonzero(),axis = 1)\n",
    "rel_matrix,rel_val = np.stack(rel_features.nonzero(),axis = 1),rel_features.data\n",
    "ent_matrix,ent_val = np.stack(adj_features.nonzero(),axis = 1),adj_features.data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T06:09:12.232398Z",
     "start_time": "2024-07-23T06:09:06.194017Z"
    }
   },
   "id": "159b5a7df8a3cf4c",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_pair))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T06:09:48.283078Z",
     "start_time": "2024-07-23T06:09:48.280162Z"
    }
   },
   "id": "3de825b985749982",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "print(len(val_pair))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T06:09:55.822223Z",
     "start_time": "2024-07-23T06:09:55.819153Z"
    }
   },
   "id": "b588c03bc3619fbc",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_pair))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T06:10:03.397740Z",
     "start_time": "2024-07-23T06:10:03.394810Z"
    }
   },
   "id": "34b73d5a91db3b5c",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest sim: 4.519999980926514 lowest sim: 0.3199999928474426\n",
      "two_d_indices:\n",
      "tensor([[2, 2],\n",
      "        [2, 1],\n",
      "        [1, 2],\n",
      "        [1, 1],\n",
      "        [2, 0],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 0]])\n",
      "vals:\n",
      "tensor([4.5200, 2.9600, 2.7800, 1.8200, 1.4000, 1.0400, 0.8600, 0.6800, 0.3200])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义相似度矩阵 (3x3)\n",
    "img_sim = torch.tensor([\n",
    "    [0.32, 0.68, 1.04],\n",
    "    [0.86, 1.82, 2.78],\n",
    "    [1.40, 2.96, 4.52]\n",
    "])\n",
    "\n",
    "# 定义 get_topk_indices 函数\n",
    "def get_topk_indices(M, K=1000):\n",
    "    H, W = M.shape\n",
    "    M_view = M.view(-1)\n",
    "    vals, indices = M_view.topk(K)\n",
    "    print(\"highest sim:\", vals[0].item(), \"lowest sim:\", vals[-1].item())\n",
    "    two_d_indices = torch.cat(((indices // W).unsqueeze(1), (indices % W).unsqueeze(1)), dim=1)\n",
    "    return two_d_indices, vals\n",
    "\n",
    "# 获取前 topk 元素及其索引\n",
    "topk = 2\n",
    "two_d_indices, vals = get_topk_indices(img_sim, topk * 100)\n",
    "\n",
    "print(\"two_d_indices:\")\n",
    "print(two_d_indices)\n",
    "print(\"vals:\")\n",
    "print(vals)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T06:30:29.563885Z",
     "start_time": "2024-07-23T06:30:29.539561Z"
    }
   },
   "id": "c35163b596db41f0",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest sim: 4.519999980926514 lowest sim: 0.3199999928474426\n",
      "two_d_indices:\n",
      "tensor([[2, 2],\n",
      "        [2, 1],\n",
      "        [1, 2],\n",
      "        [1, 1],\n",
      "        [2, 0],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 0]])\n",
      "vals:\n",
      "tensor([4.5200, 2.9600, 2.7800, 1.8200, 1.4000, 1.0400, 0.8600, 0.6800, 0.3200])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义相似度矩阵 (3x3)\n",
    "img_sim = torch.tensor([\n",
    "    [0.32, 0.68, 1.04],\n",
    "    [0.86, 1.82, 2.78],\n",
    "    [1.40, 2.96, 4.52]\n",
    "])\n",
    "\n",
    "# 定义 get_topk_indices 函数\n",
    "def get_topk_indices(M, K=1000):\n",
    "    H, W = M.shape\n",
    "    M_view = M.view(-1)\n",
    "    if K > M_view.size(0):\n",
    "        K = M_view.size(0)  # 确保 K 不超过矩阵中的元素数量\n",
    "    vals, indices = M_view.topk(K)\n",
    "    print(\"highest sim:\", vals[0].item(), \"lowest sim:\", vals[-1].item())\n",
    "    two_d_indices = torch.cat(((indices // W).unsqueeze(1), (indices % W).unsqueeze(1)), dim=1)\n",
    "    return two_d_indices, vals\n",
    "\n",
    "# 获取前 topk 元素及其索引\n",
    "topk = 2\n",
    "two_d_indices, vals = get_topk_indices(img_sim, topk * 100)\n",
    "\n",
    "print(\"two_d_indices:\")\n",
    "print(two_d_indices)\n",
    "print(\"vals:\")\n",
    "print(vals)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T06:36:31.809115Z",
     "start_time": "2024-07-23T06:36:31.800273Z"
    }
   },
   "id": "ff6573215ecd2969",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "left_ents = [0, 2, 4]\n",
    "right_ents = [1, 3, 5]\n",
    "two_d_indices = torch.tensor([[2, 2], [1, 2], [2, 1], [1, 1], [2, 0], [1, 0], [0, 2], [0, 1], [0, 0]])\n",
    "vals = torch.tensor([4.52, 2.78, 2.96, 1.82, 1.40, 0.86, 1.04, 0.68, 0.32])\n",
    "\n",
    "used_inds = []\n",
    "visual_links = []\n",
    "count = 0\n",
    "topk = 2\n",
    "\n",
    "for index in range(len(two_d_indices)):\n",
    "    ind = two_d_indices[index]\n",
    "    if left_ents[ind[0]] in used_inds: continue\n",
    "    if right_ents[ind[1]] in used_inds: continue\n",
    "    used_inds.append(left_ents[ind[0]])\n",
    "    used_inds.append(right_ents[ind[1]])\n",
    "    visual_links.append((left_ents[ind[0]], right_ents[ind[1]], vals[index].cpu(), vals[index].cpu()))\n",
    "    count += 1\n",
    "    if count == topk:\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T06:51:37.304966Z",
     "start_time": "2024-07-23T06:51:37.295373Z"
    }
   },
   "id": "34cbdb7c4de946a4",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(4, 5, tensor(4.5200), tensor(4.5200)),\n (2, 3, tensor(1.8200), tensor(1.8200))]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_links"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T06:51:42.996211Z",
     "start_time": "2024-07-23T06:51:42.991176Z"
    }
   },
   "id": "5295db9769e02a",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class evaluateTorch:\n",
    "    def __init__(self,  device, dev_pair,eval_batch_size=1024, k=10, batch=1024):\n",
    "        self.device = device\n",
    "        self.dev_pair = dev_pair\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.topk = k\n",
    "        self.batch = batch\n",
    "\n",
    "    def sim_results(self, Matrix_A, Matrix_B):\n",
    "        # A x B.t\n",
    "        A_sim = torch.mm(Matrix_A, Matrix_B.t())\n",
    "        return A_sim\n",
    "\n",
    "\n",
    "\n",
    "    def avg_results(self, Matrix_A):\n",
    "        k = 10\n",
    "        avg_results = torch.sum(torch.topk(Matrix_A, k=k)[0], dim=-1) / k\n",
    "        return avg_results\n",
    "\n",
    "    def CSLS_results(self, inputs):\n",
    "        SxT_sim, TxS_avg, SxT_avg,ans_rank = inputs\n",
    "\n",
    "        TxS_avg, SxT_avg = [torch.unsqueeze(m, dim=1) for m in [TxS_avg, SxT_avg]]\n",
    "        sim = 2 * SxT_sim - SxT_avg - TxS_avg.t()\n",
    "        # rank = torch.argsort(sim, dim=-1, descending=True)\n",
    "\n",
    "        # targets = rank[:, :self.topk]\n",
    "        # values = torch.gather(sim, 1, targets)\n",
    "\n",
    "        #     rank = tf.argsort(-sim,axis=-1)\n",
    "        #     results = tf.where(tf.equal(rank,K.cast(K.tile(ans_rank,[1,len(self.dev_pair)]),dtype=\"int32\")))\n",
    "        #     return K.expand_dims(results,axis=0)\n",
    "        # results = torch.where(torch.equal(rank, torch.tensor(ans_rank).unsqueeze(0).repeat(1, len(self.dev_pair)).int()))\n",
    "        rank = torch.argsort(-sim, dim=-1)\n",
    "        results = torch.where(torch.eq(rank, torch.tensor(ans_rank).unsqueeze(1).repeat(1, len(self.dev_pair)).to(self.device)))\n",
    "        return results[1]\n",
    "        # return torch.unsqueeze(results[1], dim=0)\n",
    "\n",
    "        # return targets.cpu().numpy(), values.cpu().numpy()\n",
    "\n",
    "    def CSLS_rank(self, inputs):\n",
    "        SxT_sim, TxS_avg, SxT_avg,ans_rank = inputs\n",
    "\n",
    "        TxS_avg, SxT_avg = [torch.unsqueeze(m, dim=1) for m in [TxS_avg, SxT_avg]]\n",
    "        sim = 2 * SxT_sim - SxT_avg - TxS_avg.t()\n",
    "        # rank = torch.argsort(sim, dim=-1, descending=True)\n",
    "\n",
    "        # targets = rank[:, :self.topk]\n",
    "        # values = torch.gather(sim, 1, targets)\n",
    "\n",
    "        #     rank = tf.argsort(-sim,axis=-1)\n",
    "        #     results = tf.where(tf.equal(rank,K.cast(K.tile(ans_rank,[1,len(self.dev_pair)]),dtype=\"int32\")))\n",
    "        #     return K.expand_dims(results,axis=0)\n",
    "        # results = torch.where(torch.equal(rank, torch.tensor(ans_rank).unsqueeze(0).repeat(1, len(self.dev_pair)).int()))\n",
    "        rank = torch.argsort(-sim, dim=-1)\n",
    "     \n",
    "        return rank[:,0]\n",
    "\n",
    "    def CSLS_cal(self, sourceVec, targetVec,m1,m2,evaluate=True):\n",
    "        batch_size = self.eval_batch_size\n",
    "        SxT_sim = []\n",
    "        TxS_sim=[]\n",
    "        for epoch in range(len(sourceVec) // batch_size + 1):\n",
    "            SxT_sim.append(self.sim_results(sourceVec[epoch * batch_size:(epoch + 1) * batch_size], targetVec))\n",
    "            TxS_sim.append(self.sim_results(targetVec[epoch * batch_size:(epoch + 1) * batch_size], sourceVec))\n",
    "\n",
    "        alpha=0.2\n",
    "        # if evaluate:\n",
    "\n",
    "        for epoch in range(len(sourceVec) // batch_size + 1):\n",
    "            SxT_sim[epoch]=SxT_sim[epoch]*(1-alpha)+m1[epoch * batch_size:(epoch + 1) * batch_size,:]*alpha\n",
    "            TxS_sim[epoch]=TxS_sim[epoch]*(1-alpha)+m2[epoch * batch_size:(epoch + 1) * batch_size,:]*alpha\n",
    "\n",
    "\n",
    "        SxT_avg = []\n",
    "        TxS_avg = []\n",
    "        for epoch in range(len(sourceVec) // batch_size + 1):\n",
    "            SxT_avg.append(self.avg_results(SxT_sim[epoch]))\n",
    "            TxS_avg.append(self.avg_results(TxS_sim[epoch]))\n",
    "\n",
    "        # SxT_sim = self.sim_results(sourceVec, targetVec)\n",
    "        # SxT_sim = SxT_sim*(1-alpha)+m*alpha\n",
    "\n",
    "        # SxT_avg = self.avg_results(SxT_sim)\n",
    "\n",
    "        # TxS_sim = self.sim_results(targetVec, sourceVec)\n",
    "        # TxS_sim = TxS_sim*(1-alpha)+m*alpha\n",
    "\n",
    "        # TxS_avg = self.avg_results(TxS_sim)\n",
    "\n",
    "\n",
    "        if evaluate:\n",
    "            targets = np.empty((0, self.topk), int)\n",
    "            targets=[]\n",
    "            for epoch in range(len(sourceVec) // batch_size + 1):\n",
    "                ans_rank = np.array([i for i in range(epoch * batch_size,min((epoch+1) * batch_size,len(sourceVec)))])\n",
    "                temp_targets = self.CSLS_results([SxT_sim[epoch].to(device=self.device),torch.cat((TxS_avg),dim=0).to(device=self.device), SxT_avg[epoch].to(device=self.device),ans_rank])\n",
    "                # targets = np.concatenate((targets, temp_targets), axis=0)\n",
    "                targets.append(temp_targets)\n",
    "                # values = np.concatenate((values, temp_values), axis=0)\n",
    "            return torch.cat((targets),0)\n",
    "        else :\n",
    "            l_rank,r_rank = [],[]\n",
    "            for epoch in range(len(sourceVec) // batch_size + 1):\n",
    "                ans_rank = np.array([i for i in range(epoch * batch_size,min((epoch+1) * batch_size,len(sourceVec)))])\n",
    "                l_rank.append(self.CSLS_rank([SxT_sim[epoch].to(device=self.device), torch.cat((TxS_avg),dim=0).to(device=self.device), SxT_avg[epoch].to(device=self.device),ans_rank]))\n",
    "                r_rank.append(self.CSLS_rank([TxS_sim[epoch].to(device=self.device), torch.cat((SxT_avg),dim=0).to(device=self.device), TxS_avg[epoch].to(device=self.device),ans_rank]))\n",
    "\n",
    "            # return np.concatenate(r_rank,axis=1)[0],np.concatenate(l_rank,axis=1)[0] \n",
    "            return  torch.cat((r_rank),dim=0).cpu().numpy(),torch.cat((l_rank),dim=0).cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T08:40:35.161854Z",
     "start_time": "2024-07-23T08:40:35.137814Z"
    }
   },
   "id": "541a6bb853dd5f5c",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Lvec = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "Rvec = torch.tensor([[2.0, 1.0], [4.0, 3.0], [6.0, 5.0]])\n",
    "img_sim_dev_boot = torch.tensor([[0.9, 0.8, 0.7], [0.6, 0.5, 0.4], [0.3, 0.2, 0.1]])\n",
    "dev_pair = [(0, 0), (1, 1), (2, 2)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T08:46:18.977963Z",
     "start_time": "2024-07-23T08:46:18.972786Z"
    }
   },
   "id": "811eebf3bd67e81e",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSLS 结果:\n",
      "[0 2 2]\n",
      "[0 2 2]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class evaluateTorch:\n",
    "    def __init__(self, device, dev_pair, eval_batch_size=1024, k=10, batch=1024):\n",
    "        self.device = device\n",
    "        self.dev_pair = dev_pair\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.topk = k\n",
    "        self.batch = batch\n",
    "\n",
    "    def sim_results(self, Matrix_A, Matrix_B):\n",
    "        # A x B.t\n",
    "        A_sim = torch.mm(Matrix_A, Matrix_B.t())\n",
    "        return A_sim\n",
    "\n",
    "    def avg_results(self, Matrix_A):\n",
    "        k = min(self.topk, Matrix_A.size(1))  # 确保 k 不超过 Matrix_A 的大小\n",
    "        avg_results = torch.sum(torch.topk(Matrix_A, k=k)[0], dim=-1) / k\n",
    "        return avg_results\n",
    "\n",
    "    def CSLS_results(self, inputs):\n",
    "        SxT_sim, TxS_avg, SxT_avg, ans_rank = inputs\n",
    "\n",
    "        TxS_avg, SxT_avg = [torch.unsqueeze(m, dim=1) for m in [TxS_avg, SxT_avg]]\n",
    "        sim = 2 * SxT_sim - SxT_avg - TxS_avg.t()\n",
    "\n",
    "        rank = torch.argsort(-sim, dim=-1)\n",
    "        results = torch.where(torch.eq(rank, torch.tensor(ans_rank).unsqueeze(1).repeat(1, len(self.dev_pair)).to(self.device)))\n",
    "        return results[1]\n",
    "\n",
    "    def CSLS_rank(self, inputs):\n",
    "        SxT_sim, TxS_avg, SxT_avg, ans_rank = inputs\n",
    "\n",
    "        TxS_avg, SxT_avg = [torch.unsqueeze(m, dim=1) for m in [TxS_avg, SxT_avg]]\n",
    "        sim = 2 * SxT_sim - SxT_avg - TxS_avg.t()\n",
    "\n",
    "        rank = torch.argsort(-sim, dim=-1)\n",
    "        return rank[:, 0]\n",
    "\n",
    "    def CSLS_cal(self, sourceVec, targetVec, m1, m2, evaluate=True):\n",
    "        batch_size = self.eval_batch_size\n",
    "        SxT_sim = []\n",
    "        TxS_sim = []\n",
    "        for epoch in range(len(sourceVec) // batch_size + 1):\n",
    "            SxT_sim.append(self.sim_results(sourceVec[epoch * batch_size:(epoch + 1) * batch_size], targetVec))\n",
    "            TxS_sim.append(self.sim_results(targetVec[epoch * batch_size:(epoch + 1) * batch_size], sourceVec))\n",
    "\n",
    "        alpha = 0.2\n",
    "        for epoch in range(len(sourceVec) // batch_size + 1):\n",
    "            SxT_sim[epoch] = SxT_sim[epoch] * (1 - alpha) + m1[epoch * batch_size:(epoch + 1) * batch_size, :] * alpha\n",
    "            TxS_sim[epoch] = TxS_sim[epoch] * (1 - alpha) + m2[epoch * batch_size:(epoch + 1) * batch_size, :] * alpha\n",
    "\n",
    "        SxT_avg = []\n",
    "        TxS_avg = []\n",
    "        for epoch in range(len(sourceVec) // batch_size + 1):\n",
    "            SxT_avg.append(self.avg_results(SxT_sim[epoch]))\n",
    "            TxS_avg.append(self.avg_results(TxS_sim[epoch]))\n",
    "\n",
    "        if evaluate:\n",
    "            targets = []\n",
    "            for epoch in range(len(sourceVec) // batch_size + 1):\n",
    "                ans_rank = np.array([i for i in range(epoch * batch_size, min((epoch + 1) * batch_size, len(sourceVec)))])\n",
    "                temp_targets = self.CSLS_results([SxT_sim[epoch].to(device=self.device), torch.cat((TxS_avg), dim=0).to(device=self.device), SxT_avg[epoch].to(device=self.device), ans_rank])\n",
    "                targets.append(temp_targets)\n",
    "            return torch.cat((targets), 0)\n",
    "        else:\n",
    "            l_rank, r_rank = [], []\n",
    "            for epoch in range(len(sourceVec) // batch_size + 1):\n",
    "                ans_rank = np.array([i for i in range(epoch * batch_size, min((epoch + 1) * batch_size, len(sourceVec)))])\n",
    "                l_rank.append(self.CSLS_rank([SxT_sim[epoch].to(device=self.device), torch.cat((TxS_avg), dim=0).to(device=self.device), SxT_avg[epoch].to(device=self.device), ans_rank]))\n",
    "                r_rank.append(self.CSLS_rank([TxS_sim[epoch].to(device=self.device), torch.cat((SxT_avg), dim=0).to(device=self.device), TxS_avg[epoch].to(device=self.device), ans_rank]))\n",
    "\n",
    "            return  torch.cat((r_rank),dim=0).cpu().numpy(),torch.cat((l_rank),dim=0).cpu().numpy()\n",
    "\n",
    "# 假设的数据\n",
    "Lvec = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "Rvec = torch.tensor([[2.0, 1.0], [4.0, 3.0], [6.0, 5.0]])\n",
    "img_sim_dev_boot = torch.tensor([[0.9, 0.8, 0.7], [0.6, 0.5, 0.4], [0.3, 0.2, 0.1]])\n",
    "dev_pair = [(0, 0), (1, 1), (2, 2)]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 创建 evaluateTorch 实例\n",
    "evaluater_torch = evaluateTorch(device, dev_pair)\n",
    "\n",
    "# 执行 CSLS 计算\n",
    "A,B = evaluater_torch.CSLS_cal(Lvec, Rvec, img_sim_dev_boot, img_sim_dev_boot.t(), evaluate=False)\n",
    "\n",
    "print(\"CSLS 结果:\")\n",
    "print(A)\n",
    "print(B)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T08:52:57.700845Z",
     "start_time": "2024-07-23T08:52:57.679319Z"
    }
   },
   "id": "8e2fad65db7c3a6b",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始向量: tensor([[ 1.6935,  1.2172, -0.0474,  ..., -0.8397,  0.7084, -0.1599],\n",
      "        [ 0.8791, -1.3297,  0.8217,  ...,  0.4250, -0.0378, -1.2609],\n",
      "        [ 0.5091, -1.7833, -0.8747,  ..., -1.0997,  0.6612,  0.4733],\n",
      "        ...,\n",
      "        [-1.2154,  0.1178,  2.8064,  ..., -0.2860,  1.5074, -1.5766],\n",
      "        [-0.9026,  0.2341, -2.3404,  ...,  0.1798,  2.3059, -0.9629],\n",
      "        [ 1.0292, -0.4149,  0.9449,  ..., -0.6257,  1.2328,  0.6047]])\n",
      "分离后的向量: tensor([[ 1.6935,  1.2172, -0.0474,  ..., -0.8397,  0.7084, -0.1599],\n",
      "        [ 0.8791, -1.3297,  0.8217,  ...,  0.4250, -0.0378, -1.2609],\n",
      "        [ 0.5091, -1.7833, -0.8747,  ..., -1.0997,  0.6612,  0.4733],\n",
      "        ...,\n",
      "        [-1.2154,  0.1178,  2.8064,  ..., -0.2860,  1.5074, -1.5766],\n",
      "        [-0.9026,  0.2341, -2.3404,  ...,  0.1798,  2.3059, -0.9629],\n",
      "        [ 1.0292, -0.4149,  0.9449,  ..., -0.6257,  1.2328,  0.6047]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个 300 维的向量\n",
    "vector = torch.randn(100,300)\n",
    "\n",
    "# 分离出一个新的张量，不会记录梯度\n",
    "detached_vector = vector.detach()\n",
    "\n",
    "# 打印张量以验证\n",
    "print(\"原始向量:\", vector)\n",
    "print(\"分离后的向量:\", detached_vector)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T09:11:47.770333Z",
     "start_time": "2024-07-23T09:11:47.753704Z"
    }
   },
   "id": "10d3f02c11605ba8",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 300])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detached_vector.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T09:11:57.568646Z",
     "start_time": "2024-07-23T09:11:57.564910Z"
    }
   },
   "id": "97b78da73ea7969e",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top rank indices for each source:\n",
      "tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def CSLS_rank(inputs):\n",
    "    SxT_sim, TxS_avg, SxT_avg, ans_rank = inputs\n",
    "\n",
    "    # 将 TxS_avg 和 SxT_avg 变为列向量\n",
    "    TxS_avg, SxT_avg = [torch.unsqueeze(m, dim=1) for m in [TxS_avg, SxT_avg]]\n",
    "\n",
    "    # 计算 CSLS 相似度矩阵\n",
    "    sim = 2 * SxT_sim - SxT_avg - TxS_avg.t()\n",
    "\n",
    "    # 对每行进行降序排序，返回排序后的索引\n",
    "    rank = torch.argsort(-sim, dim=-1)\n",
    "\n",
    "    # 返回每行中相似度最高的目标索引\n",
    "    return rank[:, 0]\n",
    "\n",
    "# 示例数据\n",
    "SxT_sim = torch.tensor([[0.9, 0.8, 0.7],\n",
    "                        [0.6, 0.5, 0.4],\n",
    "                        [0.3, 0.2, 0.1]])\n",
    "\n",
    "TxS_avg = torch.tensor([0.6, 0.5, 0.4])\n",
    "SxT_avg = torch.tensor([0.8, 0.5, 0.2])\n",
    "ans_rank = torch.tensor([0, 1, 2])  # 示例答案排名\n",
    "\n",
    "# 输入数据\n",
    "inputs = (SxT_sim, TxS_avg, SxT_avg, ans_rank)\n",
    "\n",
    "# 计算排名\n",
    "top_rank = CSLS_rank(inputs)\n",
    "\n",
    "print(\"Top rank indices for each source:\")\n",
    "print(top_rank)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-23T10:07:36.018882Z",
     "start_time": "2024-07-23T10:07:35.996214Z"
    }
   },
   "id": "52ddd9eca4e2f",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5428982dc63fde57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
